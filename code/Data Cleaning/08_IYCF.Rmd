---
title: "08_IYCF"
output:
  word_document: default
  html_document: default
---

#Loading Libraries
```{r}
library(dplyr)
library(tidyr)
library(stringr)
library(readr)
library(here)
library(ggplot2)


```
#Load Dataset 
```{r}

icy_df <- read_csv(here("data", "raw", "iycf_national_zaf.csv"))
```

#Display Dataset content
```{r}
head(icy_df)
```

#Remove the first row(meta data)
```{r}
icy_df <- icy_df[-1, ]
```
#dimensions 
```{r}
dim(icy_df)
```
# Inspect Duplicated rows
```{r}
dup_check <- icy_df %>%
  group_by(Indicator, SurveyYear, CharacteristicId, Value) %>%
  filter(n() > 1)

dup_check

```

```{r}
icy_df <- icy_df %>%
  distinct(Indicator, SurveyYear, CharacteristicId, Value, .keep_all = TRUE)

```
# Missing Values
```{r handle_missing_icy, cache=FALSE}
# 1. Remove completely empty columns
icy_df <- icy_df %>% select(where(~!all(is.na(.))))

# 2. Impute numeric columns with median
num_cols <- icy_df %>% select(where(is.numeric)) %>% names()
icy_df <- icy_df %>%
  mutate(across(all_of(num_cols), ~ ifelse(is.na(.), median(., na.rm = TRUE), .)))

# 3. Impute character/categorical columns with mode
cat_cols <- icy_df %>% select(where(is.character)) %>% names()
get_mode <- function(x) {
  ux <- na.omit(x)
  if(length(ux) == 0) return(NA_character_)
  names(sort(table(ux), decreasing = TRUE))[1]
}
icy_df <- icy_df %>%
  mutate(across(all_of(cat_cols), ~ ifelse(is.na(.), get_mode(.), .)))

# 4. Summary after handling missing values
missing_summary <- data.frame(
  Column = names(icy_df),
  Missing_Percentage = paste0(round(colMeans(is.na(icy_df)) * 100, 2), "%"),
  Missing_Count = colSums(is.na(icy_df))
)

cat("Total remaining NAs:", sum(is.na(icy_df)), "\n")
cat("Missing value summary per column:\n")
print(missing_summary)


```

```{r}
data.frame(
  Column = names(icy_df),
  Missing_Data = paste0(colSums(is.na(icy_df)))
  )
```

#check data types
```{r}
data.frame(
  Column = names(icy_df),
  paste0(sapply(icy_df, typeof))
)

```
#Check The structure of the dataset 
```{r}
str(icy_df)

```
#Convert Data Types
```{r}
icy_df <- icy_df %>%
  mutate(
        Value = as.numeric(Value),
    Precision = as.numeric(Precision),
    SurveyYear = as.integer(SurveyYear),
    IndicatorOrder = as.integer(IndicatorOrder),
    CharacteristicId = as.integer(CharacteristicId),
    CharacteristicOrder = as.integer(CharacteristicOrder),
    IsTotal = as.logical(as.integer(IsTotal)),
    IsPreferred = as.logical(as.integer(IsPreferred)),
    SurveyYearLabel = as.integer(SurveyYearLabel),
    DenominatorWeighted = as.numeric(DenominatorWeighted),
    DenominatorUnweighted = as.numeric(DenominatorUnweighted),
  )
```
#check for unique values
```{r}
library(dplyr)
library(purrr)

# Summary table: column name, number of unique values, sample of unique values
n_sample <- 3

summary_tbl <- icy_df %>%
  map_df(~ tibble(
    n_unique = n_distinct(.),
    sample_values = paste(head(unique(.), n_sample), collapse = ", ")
  ), .id = "column")


summary_tbl


```

# Drop the Redundant Columns
```{r}
icy_df <- icy_df %>%
  select(
    -ISO3, 
    -DHS_CountryCode, 
    -CountryName, 
    -SurveyId,
    -ByVariableId, 
    
    -IsTotal,
    
    -SurveyYearLabel, 
    -SurveyType,
    -CharacteristicOrder
    
  )
```
- Columns removed because they were constant, redundant, or not analytically useful:

- ISO3, DHS_CountryCode, CountryName, SurveyId, ByVariableId, IsTotal, SurveyYearLabel, SurveyType, CharacteristicOrder

- These columns either contained a single value, duplicated information, or survey metadata that does not impact analysis.
# Assumed pattern, the missing values can be filled with the previous non missing value in the opposite attribute
```{r}


library(dplyr)
library(tidyr)

icy_df <- icy_df %>%
  fill(DenominatorWeighted, DenominatorUnweighted, .direction = "up")

icy_df[
       c("DataId","DenominatorWeighted", "DenominatorUnweighted")]

```

```{r}
ggplot(icy_df, aes(x = DenominatorWeighted, y = DenominatorUnweighted)) +
  geom_point(alpha = 0.6, color = "steelblue") +
  labs(title = "Scatterplot for Outlier Detection",
       x = "Denominator Weighted",
       y = "Denominator Unweighted") +
  theme_minimal()


ggplot(icy_df, aes(y = DenominatorWeighted)) +
  geom_boxplot(fill = "lightblue", outlier.color = "red", outlier.shape = 16) +
  labs(title = "Boxplot of Denominator Weighted",
       y = "Denominator Weighted") +
  theme_minimal()
```

```{r}
dim(icy_df)
```
#Outlier Handling
```{r}
# Calculate IQR boundaries
Q1_w <- quantile(icy_df$DenominatorWeighted, 0.25, na.rm = TRUE)
Q3_w <- quantile(icy_df$DenominatorWeighted, 0.75, na.rm = TRUE)
IQR_w <- Q3_w - Q1_w
lower_w <- Q1_w - 1.5 * IQR_w
upper_w <- Q3_w + 1.5 * IQR_w

Q1_uw <- quantile(icy_df$DenominatorUnweighted, 0.25, na.rm = TRUE)
Q3_uw <- quantile(icy_df$DenominatorUnweighted, 0.75, na.rm = TRUE)
IQR_uw <- Q3_uw - Q1_uw
lower_uw <- Q1_uw - 1.5 * IQR_uw
upper_uw <- Q3_uw + 1.5 * IQR_uw

# Cap values to the IQR limits
icy_df <- icy_df %>%
  mutate(
    DenominatorWeighted = pmin(pmax(DenominatorWeighted, lower_w), upper_w),
    DenominatorUnweighted = pmin(pmax(DenominatorUnweighted, lower_uw), upper_uw)
  )


```

Problem: DenominatorWeighted and DenominatorUnweighted contained extreme values that could skew analyses.

Solution: IQR-based capping:

Calculate bounds:

- Lower bound = Q1 – 1.5 × IQR
- Upper bound = Q3 + 1.5 × IQR

- Cap extreme values:

- Values below lower bound → set to lower bound

- Values above upper bound → set to upper bound

- Visualize: Scatterplots and boxplots were used to confirm the effect of outlier capping.

- Outcome: Extreme values were mitigated while retaining all rows, improving robustness for analysis.
#save cleaned data
```{r}
write_csv(icy_df, here("data","processed", "iycf_cleaned.csv"))
```
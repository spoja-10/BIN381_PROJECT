---
title: "04_covid_prevention"
output: html_document
---

# Covid 19 Prevention

## Load Libraries

```{r }
# Data manipulation
library(dplyr)
library(tidyr)
library(readr)
library(here)
library(purrr)

# Visualization and summaries
library(ggplot2)
library(skimr)
library(visdat)
```

## Load Data
```{r}
# Load the COVID-19 prevention dataset
# Load the COVID-19 prevention dataset, skipping first row if it contains metadata
covid_df <- read_csv(
  here("data", "raw", "covid-19-prevention_national_zaf.csv"),
  skip = 1,            # skip metadata row
  col_types = cols()   # suppress guessing messages
)

cat("COVID-19 prevention dataset loaded successfully.\n")
cat("Dimensions:", dim(covid_df), "\n")

```
## Initial Data Assessment and Column Renaming

```{r}
# Quick glimpse of dataset
glimpse(covid_df)

# Summary of missingness
skim(covid_df)

# visualize missing values
vis_miss(covid_df)

# Rename unnamed columns (...6, ...11, etc.) to meaningful names
covid_df <- covid_df %>%
  rename_with(~paste0("col_", seq_along(.)), .cols = everything())

cat("Columns renamed systematically.\n")
cat("New column names:\n")
print(colnames(covid_df))

```
## Rename Columns Meaningfully
```{r}
# Replace generic col_1, col_2, ... with actual names
colnames(covid_df) <- c(
  "iso3", "data_id", "indicator", "value", "precision",
  "dhs_country_code", "country_name", "survey_year", "survey_id",
  "indicator_id", "indicator_order", "indicator_type", "characteristic_id",
  "characteristic_order", "characteristic_category", "characteristic_label",
  "by_variable_id", "by_variable_label", "is_total", "is_preferred",
  "sdrid", "region_id", "survey_year_label", "survey_type",
  "denominator_weighted", "denominator_unweighted", "ci_low", "ci_high",
  "level_rank"
)

cat("Columns renamed to meaningful names.\n")
print(colnames(covid_df))
```

## Handle Duplicates

```{r}
# Check for exact duplicates
exact_dups <- sum(duplicated(covid_df))
cat("Exact duplicate rows:", exact_dups, "\n")

# Check for semantic duplicates (same indicator, survey_year, characteristic_id, value)
semantic_dups <- covid_df %>%
  group_by(indicator, survey_year, characteristic_id, value) %>%
  filter(n() > 1) %>%
  ungroup()

cat("Semantic duplicate groups:", nrow(semantic_dups), "\n")

# Remove all duplicates, keeping first occurrence
covid_df <- covid_df %>%
  distinct(indicator, survey_year, characteristic_id, value, .keep_all = TRUE)

cat("Dimensions after duplicate removal:", dim(covid_df), "\n")


```

## Convert Data Types
```{r}
# Convert numeric columns
covid_df <- covid_df %>%
  mutate(
    across(c(value, precision, denominator_weighted, denominator_unweighted,
             ci_low, ci_high), as.numeric),
    across(c(survey_year, indicator_order, characteristic_id,
             characteristic_order, survey_year_label, by_variable_id), as.integer),
    across(c(is_total, is_preferred), ~as.logical(as.integer(.)))
  )

# Quick check of new types
str(covid_df)
```

## Handle Missing Values
```{r}
# Visualize missingness
library(visdat)
vis_miss(covid_df)

# Summarize missing values
missing_summary <- covid_df %>%
  summarise(across(everything(), ~sum(is.na(.)))) %>%
  pivot_longer(everything(), names_to = "column", values_to = "n_missing") %>%
  mutate(total_rows = nrow(covid_df),
         missing_percent = round(n_missing / total_rows * 100, 2))

missing_summary %>% arrange(desc(missing_percent))


```

```{r}
covid_df <- covid_df %>%
  select(where(~!all(is.na(.))))

# Check remaining missing values
missing_summary <- covid_df %>%
  summarise(across(everything(), ~sum(is.na(.)))) %>%
  pivot_longer(cols = everything(), names_to = "column", values_to = "n_missing") %>%
  mutate(
    total_rows = nrow(covid_df),
    missing_percent = round(n_missing / total_rows * 100, 2)
  )

## Handle Remaining Missing Values

# Impute missing survey_year_label with survey_year if available
covid_df <- covid_df %>%
  mutate(
    survey_year_label = ifelse(is.na(survey_year_label), survey_year, survey_year_label)
  )

# For survey_type, if missing, set as "Unknown"
covid_df <- covid_df %>%
  mutate(
    survey_type = ifelse(is.na(survey_type), "Unknown", survey_type)
  )

cat("Missing values addressed.\n")



# Recalculate missing values
missing_summary <- data.frame(
  Column = colnames(covid_df),
  n_missing = colSums(is.na(covid_df)),
  total_rows = nrow(covid_df),
  missing_percent = round(colSums(is.na(covid_df))/nrow(covid_df)*100, 2)
)

missing_summary %>% arrange(desc(missing_percent))
```

## Handle Outliers
```{r}
# Quick check for extreme values in 'value' and denominators
summary(covid_df$value)
summary(covid_df$denominator_weighted)
summary(covid_df$denominator_unweighted)

# Identify potential outliers using IQR method
outliers <- covid_df %>%
  filter(value > quantile(value, 0.75, na.rm = TRUE) + 1.5 * IQR(value, na.rm = TRUE) |
         value < quantile(value, 0.25, na.rm = TRUE) - 1.5 * IQR(value, na.rm = TRUE))

cat("Potential outlier rows in 'value':", nrow(outliers), "\n")

```
## Handle Noise & Special Values
```{r}
covid_df <- covid_df %>%
  mutate(
    is_total = ifelse(is_total %in% c(TRUE, FALSE), is_total, NA),
    is_preferred = ifelse(is_preferred %in% c(TRUE, FALSE), is_preferred, NA)
  )

cat("Noise and special values handled.\n")
```

## Final Validation 
```{r}
## Final Dataset Check Before Saving (existing columns only)

# Check dataset dimensions and structure
cat("Final dataset dimensions:", dim(covid_df), "\n")
str(covid_df)

# Identify numeric columns that exist
numeric_cols <- covid_df %>% select(where(is.numeric)) %>% colnames()

# Summarize numeric columns for final inspection
summary(select(covid_df, all_of(numeric_cols)))

# Confirm no remaining missing values in all columns
missing_summary <- covid_df %>%
  summarise(across(everything(), ~sum(is.na(.)))) %>%
  pivot_longer(cols = everything(), names_to = "column", values_to = "n_missing") %>%
  mutate(
    total_rows = nrow(covid_df),
    missing_percent = round(n_missing / total_rows * 100, 2)
  )

missing_summary %>% arrange(desc(missing_percent))

```

## Save Dataset
```{r save_cleaned_data}
# Define path to save cleaned CSV
clean_path <- here("data", "processed", "covid_prevention_cleaned_zaf.csv")

# Create folder if it doesn't exist
if(!dir.exists(dirname(clean_path))) dir.create(dirname(clean_path), recursive = TRUE)

# Write cleaned dataset
write_csv(covid_df, clean_path)

cat("Cleaned COVID-19 prevention dataset saved successfully at:\n", clean_path, "\n")

```